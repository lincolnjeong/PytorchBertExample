{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BertForSequenceClassification 예제","provenance":[{"file_id":"/v2/external/notebooks/welcome.ipynb","timestamp":1576484668355}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"UZ5XqGp4hzBr","colab_type":"code","outputId":"6b47ab7c-5403-46b4-c42b-ebc702652c33","executionInfo":{"status":"ok","timestamp":1576556547636,"user_tz":-540,"elapsed":19466,"user":{"displayName":"이재복","photoUrl":"","userId":"12489712164627178497"}},"colab":{"base_uri":"https://localhost:8080/","height":719}},"source":["!pip install pytorch-transformers"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting pytorch-transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n","\u001b[K     |████████████████████████████████| 184kB 45.4MB/s \n","\u001b[?25hCollecting regex\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/db/4b29a0adec5881542cd81cb5d1929b5c0787003c5740b3c921e627d9c2e5/regex-2019.12.9.tar.gz (669kB)\n","\u001b[K     |████████████████████████████████| 675kB 49.5MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.21.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.28.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.17.4)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.3.1)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n","\u001b[K     |████████████████████████████████| 860kB 52.3MB/s \n","\u001b[?25hCollecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 53.3MB/s \n","\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.10.36)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2019.11.28)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.14.1)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.2.1)\n","Requirement already satisfied: botocore<1.14.0,>=1.13.36 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.13.36)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.9.4)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.36->boto3->pytorch-transformers) (0.15.2)\n","Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.36->boto3->pytorch-transformers) (2.6.1)\n","Building wheels for collected packages: regex, sacremoses\n","  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for regex: filename=regex-2019.12.9-cp36-cp36m-linux_x86_64.whl size=609178 sha256=9c864e29475463f3034447d578e484116a9c6b02e1ea491c6c5b23ea8db1677f\n","  Stored in directory: /root/.cache/pip/wheels/0d/fb/b3/a89169557229468c49ca64f6839418f22461f6ee0a74f342b1\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=e222f21e9e49a5caf795328cb54fca5d047a7dc00fe342bf781abb7422185eb9\n","  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n","Successfully built regex sacremoses\n","Installing collected packages: regex, sacremoses, sentencepiece, pytorch-transformers\n","Successfully installed pytorch-transformers-1.2.0 regex-2019.12.9 sacremoses-0.0.35 sentencepiece-0.1.85\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F1EDE73Tj0qa","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from pytorch_transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n","from torch.optim import Adam\n","import torch.nn.functional as F"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1RS5jL4SkhOc","colab_type":"code","outputId":"1bf7ffe8-4861-44ad-a7f5-d2494d421c68","executionInfo":{"status":"ok","timestamp":1576556564405,"user_tz":-540,"elapsed":36206,"user":{"displayName":"이재복","photoUrl":"","userId":"12489712164627178497"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["# naver sentiment corpus\n","!git clone https://github.com/e9t/nsmc.git"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Cloning into 'nsmc'...\n","remote: Enumerating objects: 14763, done.\u001b[K\n","remote: Total 14763 (delta 0), reused 0 (delta 0), pack-reused 14763\u001b[K\n","Receiving objects: 100% (14763/14763), 56.19 MiB | 6.92 MiB/s, done.\n","Resolving deltas: 100% (1749/1749), done.\n","Checking out files: 100% (14737/14737), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KvdtqYt5mmQo","colab_type":"code","outputId":"2f5a2835-d7f6-4eaa-9fc3-43e8230783f7","executionInfo":{"status":"ok","timestamp":1576556565534,"user_tz":-540,"elapsed":37324,"user":{"displayName":"이재복","photoUrl":"","userId":"12489712164627178497"}},"colab":{"base_uri":"https://localhost:8080/","height":142}},"source":["train_df = pd.read_csv('./nsmc/ratings_train.txt', sep='\\t')\n","test_df = pd.read_csv('./nsmc/ratings_test.txt', sep='\\t')\n","train_df.head(3)"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9976970</td>\n","      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3819312</td>\n","      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10265843</td>\n","      <td>너무재밓었다그래서보는것을추천한다</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         id                           document  label\n","0   9976970                아 더빙.. 진짜 짜증나네요 목소리      0\n","1   3819312  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n","2  10265843                  너무재밓었다그래서보는것을추천한다      0"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"RLX6F44fzW7h","colab_type":"code","colab":{}},"source":["train_df.dropna(inplace=True)\n","test_df.dropna(inplace=True)\n","\n","train_df = train_df.sample(frac=0.4, random_state=999)\n","test_df = test_df.sample(frac=0.4, random_state=999)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PcFrRk6I0Ouz","colab_type":"code","colab":{}},"source":["class NsmcDataset(Dataset):\n","    ''' Naver Sentiment Movie Corpus Dataset '''\n","    def __init__(self, df):\n","        self.df = df\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        text = self.df.iloc[idx, 1]\n","        label = self.df.iloc[idx, 2]\n","        return text, label"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FIuykKZj6vIg","colab_type":"code","colab":{}},"source":["nsmc_train_dataset = NsmcDataset(train_df)\n","train_loader = DataLoader(nsmc_train_dataset, batch_size=2, shuffle=True, num_workers=2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7gULDMqn9DAw","colab_type":"code","outputId":"63f08ae8-869c-4163-f363-982ab69411b9","executionInfo":{"status":"ok","timestamp":1576556652251,"user_tz":-540,"elapsed":123976,"user":{"displayName":"이재복","photoUrl":"","userId":"12489712164627178497"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["device = torch.device(\"cuda\")\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n","model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased')\n","model.to(device)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["100%|██████████| 995526/995526 [00:01<00:00, 759386.29B/s]\n","100%|██████████| 521/521 [00:00<00:00, 179293.76B/s]\n","100%|██████████| 714314041/714314041 [01:05<00:00, 10861633.61B/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"XmK-ZPvcbvOM","colab_type":"code","outputId":"cfd2c604-7bee-47e8-b5c1-bd6a5853d3f7","executionInfo":{"status":"ok","timestamp":1576568726895,"user_tz":-540,"elapsed":10245750,"user":{"displayName":"이재복","photoUrl":"","userId":"12489712164627178497"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["optimizer = Adam(model.parameters(), lr=1e-6)\n","\n","itr = 1\n","p_itr = 500\n","epochs = 1\n","total_loss = 0\n","total_len = 0\n","total_correct = 0\n","\n","\n","model.train()\n","for epoch in range(epochs):\n","    \n","    for text, label in train_loader:\n","        optimizer.zero_grad()\n","\n","        encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n","        padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n","        sample = torch.tensor(padded_list)\n","        sample, label = sample.to(device), label.to(device)\n","        labels = torch.tensor(label)\n","        outputs = model(sample, labels=labels)\n","        loss, logits = outputs\n","\n","        pred = torch.argmax(F.softmax(logits), dim=1)\n","        correct = pred.eq(labels)\n","        total_correct += correct.sum().item()\n","        total_len += len(labels)\n","        total_loss += loss.item()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        if itr % p_itr == 0:\n","            print('[Epoch {}/{}] Iteration {} -> Train Loss: {:.4f}, Accuracy: {:.3f}'.format(epoch+1, epochs, itr, total_loss/p_itr, total_correct/total_len))\n","            total_loss = 0\n","            total_len = 0\n","            total_correct = 0\n","\n","        itr+=1"],"execution_count":9,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["[Epoch 1/1] Iteration 500 -> Train Loss: 0.6946, Accuracy: 0.527\n","[Epoch 1/1] Iteration 1000 -> Train Loss: 0.6933, Accuracy: 0.518\n","[Epoch 1/1] Iteration 1500 -> Train Loss: 0.6906, Accuracy: 0.543\n","[Epoch 1/1] Iteration 2000 -> Train Loss: 0.6806, Accuracy: 0.587\n","[Epoch 1/1] Iteration 2500 -> Train Loss: 0.6334, Accuracy: 0.639\n","[Epoch 1/1] Iteration 3000 -> Train Loss: 0.6093, Accuracy: 0.686\n","[Epoch 1/1] Iteration 3500 -> Train Loss: 0.5840, Accuracy: 0.703\n","[Epoch 1/1] Iteration 4000 -> Train Loss: 0.5619, Accuracy: 0.718\n","[Epoch 1/1] Iteration 4500 -> Train Loss: 0.5526, Accuracy: 0.729\n","[Epoch 1/1] Iteration 5000 -> Train Loss: 0.5514, Accuracy: 0.732\n","[Epoch 1/1] Iteration 5500 -> Train Loss: 0.5146, Accuracy: 0.753\n","[Epoch 1/1] Iteration 6000 -> Train Loss: 0.5586, Accuracy: 0.715\n","[Epoch 1/1] Iteration 6500 -> Train Loss: 0.5173, Accuracy: 0.756\n","[Epoch 1/1] Iteration 7000 -> Train Loss: 0.4933, Accuracy: 0.757\n","[Epoch 1/1] Iteration 7500 -> Train Loss: 0.5165, Accuracy: 0.756\n","[Epoch 1/1] Iteration 8000 -> Train Loss: 0.5096, Accuracy: 0.750\n","[Epoch 1/1] Iteration 8500 -> Train Loss: 0.5170, Accuracy: 0.746\n","[Epoch 1/1] Iteration 9000 -> Train Loss: 0.4980, Accuracy: 0.751\n","[Epoch 1/1] Iteration 9500 -> Train Loss: 0.4775, Accuracy: 0.781\n","[Epoch 1/1] Iteration 10000 -> Train Loss: 0.4642, Accuracy: 0.780\n","[Epoch 1/1] Iteration 10500 -> Train Loss: 0.4924, Accuracy: 0.769\n","[Epoch 1/1] Iteration 11000 -> Train Loss: 0.4690, Accuracy: 0.776\n","[Epoch 1/1] Iteration 11500 -> Train Loss: 0.4544, Accuracy: 0.791\n","[Epoch 1/1] Iteration 12000 -> Train Loss: 0.4687, Accuracy: 0.772\n","[Epoch 1/1] Iteration 12500 -> Train Loss: 0.4703, Accuracy: 0.776\n","[Epoch 1/1] Iteration 13000 -> Train Loss: 0.4422, Accuracy: 0.801\n","[Epoch 1/1] Iteration 13500 -> Train Loss: 0.4643, Accuracy: 0.765\n","[Epoch 1/1] Iteration 14000 -> Train Loss: 0.4788, Accuracy: 0.767\n","[Epoch 1/1] Iteration 14500 -> Train Loss: 0.4244, Accuracy: 0.794\n","[Epoch 1/1] Iteration 15000 -> Train Loss: 0.4346, Accuracy: 0.799\n","[Epoch 1/1] Iteration 15500 -> Train Loss: 0.4442, Accuracy: 0.786\n","[Epoch 1/1] Iteration 16000 -> Train Loss: 0.4659, Accuracy: 0.784\n","[Epoch 1/1] Iteration 16500 -> Train Loss: 0.4428, Accuracy: 0.790\n","[Epoch 1/1] Iteration 17000 -> Train Loss: 0.4304, Accuracy: 0.790\n","[Epoch 1/1] Iteration 17500 -> Train Loss: 0.4431, Accuracy: 0.798\n","[Epoch 1/1] Iteration 18000 -> Train Loss: 0.4227, Accuracy: 0.800\n","[Epoch 1/1] Iteration 18500 -> Train Loss: 0.4139, Accuracy: 0.807\n","[Epoch 1/1] Iteration 19000 -> Train Loss: 0.4204, Accuracy: 0.802\n","[Epoch 1/1] Iteration 19500 -> Train Loss: 0.4136, Accuracy: 0.806\n","[Epoch 1/1] Iteration 20000 -> Train Loss: 0.4276, Accuracy: 0.800\n","[Epoch 1/1] Iteration 20500 -> Train Loss: 0.4442, Accuracy: 0.794\n","[Epoch 1/1] Iteration 21000 -> Train Loss: 0.4303, Accuracy: 0.796\n","[Epoch 1/1] Iteration 21500 -> Train Loss: 0.4511, Accuracy: 0.796\n","[Epoch 1/1] Iteration 22000 -> Train Loss: 0.4378, Accuracy: 0.801\n","[Epoch 1/1] Iteration 22500 -> Train Loss: 0.4248, Accuracy: 0.810\n","[Epoch 1/1] Iteration 23000 -> Train Loss: 0.4290, Accuracy: 0.803\n","[Epoch 1/1] Iteration 23500 -> Train Loss: 0.3957, Accuracy: 0.817\n","[Epoch 1/1] Iteration 24000 -> Train Loss: 0.4404, Accuracy: 0.794\n","[Epoch 1/1] Iteration 24500 -> Train Loss: 0.4165, Accuracy: 0.806\n","[Epoch 1/1] Iteration 25000 -> Train Loss: 0.4156, Accuracy: 0.805\n","[Epoch 1/1] Iteration 25500 -> Train Loss: 0.3978, Accuracy: 0.817\n","[Epoch 1/1] Iteration 26000 -> Train Loss: 0.4154, Accuracy: 0.788\n","[Epoch 1/1] Iteration 26500 -> Train Loss: 0.4203, Accuracy: 0.796\n","[Epoch 1/1] Iteration 27000 -> Train Loss: 0.3860, Accuracy: 0.822\n","[Epoch 1/1] Iteration 27500 -> Train Loss: 0.4112, Accuracy: 0.816\n","[Epoch 1/1] Iteration 28000 -> Train Loss: 0.4023, Accuracy: 0.820\n","[Epoch 1/1] Iteration 28500 -> Train Loss: 0.4119, Accuracy: 0.821\n","[Epoch 1/1] Iteration 29000 -> Train Loss: 0.4163, Accuracy: 0.808\n","[Epoch 1/1] Iteration 29500 -> Train Loss: 0.3842, Accuracy: 0.821\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jvLgd9qdrV3A","colab_type":"code","outputId":"13d6c0c0-1d5c-48d0-d445-8ef57cd0b1f4","executionInfo":{"status":"ok","timestamp":1576569728605,"user_tz":-540,"elapsed":1001757,"user":{"displayName":"이재복","photoUrl":"","userId":"12489712164627178497"}},"colab":{"base_uri":"https://localhost:8080/","height":109}},"source":["# evaluation\n","model.eval()\n","\n","nsmc_eval_dataset = NsmcDataset(test_df)\n","eval_loader = DataLoader(nsmc_eval_dataset, batch_size=2, shuffle=False, num_workers=2)\n","\n","total_loss = 0\n","total_len = 0\n","total_correct = 0\n","\n","for text, label in eval_loader:\n","    encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n","    padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n","    sample = torch.tensor(padded_list)\n","    sample, label = sample.to(device), label.to(device)\n","    labels = torch.tensor(label)\n","    outputs = model(sample, labels=labels)\n","    _, logits = outputs\n","\n","    pred = torch.argmax(F.softmax(logits), dim=1)\n","    correct = pred.eq(labels)\n","    total_correct += correct.sum().item()\n","    total_len += len(labels)\n","\n","print('Test accuracy: ', total_correct / total_len)\n"," "],"execution_count":10,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  from ipykernel import kernelapp as app\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["Test accuracy:  0.8180409020451023\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"33xBTcv5_GDQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}